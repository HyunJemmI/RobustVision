# Contrastive Learningì„ í™œìš©í•œ Light-Noise Robust Traing Method

SimCLR ê¸°ë°˜ Flow-matching idea ì‚¬ìš©

# Flow
1. Light-Noiseê°€ ì‰½ê²Œ ì¡´ì¬í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì— ëŒ€í•œ datasetì„ ê¸°ë°˜ìœ¼ë¡œ (BDD100K) Noise ì¦ê°•(Bloom, Glare, Gamma) 
2. contrastive learningì„ í†µí•œ noise í™˜ê²½ì—ì„œë„ ê°™ì€ image feature ì¶”ì¶œ 
3. downstream(TuSimple dataset ì‚¬ìš©) : lane-detection taskë¥¼ ìˆ˜í–‰í•˜ë„ë¡ fine tuning
4. noise augmentation 2 (TuSimple)
5. downstream test â†’ noise augmentation 2 dataset(noise augmented TuSimple)
6. Tusimple datasetì—ì„œ â†’ noise ì¶”ê°€í•œ imgì™€ ì›ë³¸ ì‚¬ì§„ ê°„ cosine similarityë¥¼ ë¹„êµ
7. ì´í›„ ìœ ì‚¬ë„ê°€ ë†’ì€ë°ë„ ë†’ì€ noiseì—ì„œ ì‚¬ì§„ì„ ì œëŒ€ë¡œ ê²€ì¶œí•˜ëŠ”ì§€ ë¹„êµ (ë²¤ì¹˜ë§ˆí‚¹)

# GPT-based Model Feature
## **ğŸ§  SimCLR ê¸°ë°˜ Noise-Robust ëª¨ë¸ ì„¤ê³„ ìš”ì•½**

### **1. âœ… ëª¨ë¸ êµ¬ì¡° (ResNet18 + Projector)**

- **Backbone**: ResNet-18ì—ì„œ AvgPool, FC layer ì œê±°
    
    â†’ Classification ëŒ€ì‹  **feature representation ì¶”ì¶œ**ì— ì§‘ì¤‘
    
    â†’ ì¶œë ¥: [B, 512, 7, 7]
    
- **AdaptiveAvgPool2d((1,1))**
    
    â†’ ì…ë ¥ í•´ìƒë„ì™€ ë¬´ê´€í•˜ê²Œ í•­ìƒ [B, 512, 1, 1]ìœ¼ë¡œ ì••ì¶•
    
    â†’ ì´í›„ flatten()ì„ í†µí•´ [B, 512] feature ë²¡í„° í™•ë³´
    
- **Projector Head**:
    
    Linear(512â†’512) â†’ BN â†’ ReLU â†’ Linear(512â†’256) â†’ BN(no affine)
    
    â†’ SimCLR ë…¼ë¬¸ ê¸°ë°˜ êµ¬ì„±
    
    â†’ Nonlinearity + ì •ê·œí™” í†µí•œ í•™ìŠµ ì•ˆì •ì„± í™•ë³´
    

---

### **2. ğŸ”¥ NT-Xent Loss êµ¬ì„±**

- **Cosine Similarity ê¸°ë°˜** ìœ ì‚¬ë„ ê³„ì‚°
    
    â†’ Positive pair ìœ ì‚¬ë„ëŠ” ë†’ì´ê³ , Negative pairëŠ” ë‚®ì¶¤
    
- temperature (T) íŒŒë¼ë¯¸í„° ë„ì…
    
    â†’ ìœ ì‚¬ë„ ë¶„í¬ sharpness ì¡°ì ˆ
    
    â†’ ì‘ì„ìˆ˜ë¡ ëª¨ë¸ì´ ë” ë¯¼ê°í•˜ê²Œ positive/negative êµ¬ë¶„
    
    â†’ ì‹¤í—˜ì ìœ¼ë¡œ T=0.35 ì‚¬ìš© (0.07~0.5 ì‚¬ì´ ê¶Œì¥)
    

---

### **3. ğŸ§ª Input ë° Transform**

- ì´ë¯¸ì§€ì— **ì´ë¯¸ noise augmentationì´ ì ìš©ëœ ìƒíƒœ**
    
    â†’ ì¶”ê°€ì ì¸ transformì€ ì œì™¸
    
    â†’ ë‹¨ìˆœíˆ Resize(224) + Normalizeë§Œ ì ìš©
    

---

### **4. âš™ï¸ ê¸°íƒ€ í•™ìŠµ ì•ˆì •ì„± ìš”ì†Œ**

- **AMP(Auto Mixed Precision)**
    
    â†’ NVIDIA 6000 ADA GPU ì‚¬ìš© ì‹œ ìë™ í™œì„±í™”
    
    â†’ ì—°ì‚° ì†ë„ ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ ê°œì„ 
    
- **Gradient Accumulation**
    
    â†’ batch_size=256, accum_steps=2 â†’ ìœ íš¨ ë°°ì¹˜ í¬ê¸° 512
    
- **Collapse ê²½ê³  ê°ì§€**
    
    â†’ neg_cos í‰ê· ê°’ì´ íŠ¹ì • ì„ê³„ì¹˜(0.3) ì´ìƒì¼ ê²½ìš° collapse ê°€ëŠ¥ì„± ì¶œë ¥
    
- **Early Stopping**
    
    â†’ validation loss ê¸°ì¤€, best ëª¨ë¸ ì €ì¥ ë° ì¡°ê¸° ì¢…ë£Œ

**ë‘ ëª¨ë¸ í•™ìŠµ ë°©ì‹ì˜ í•µì‹¬ ì°¨ì´ì **

1. **ë°±ë³¸ ì´ˆê¸°í™”(Pre-training)**
    - **Baseline**: ResNet-18ì„ ImageNet ì§€ë„í•™ìŠµ(pretrained) ê°€ì¤‘ì¹˜ë¡œ ì´ˆê¸°í™” â†’ DeepLabV3 ì „ì²´(ë°±ë³¸+í—¤ë“œ) fine-tune
    - **SimCLR**: ResNet-18ì„ SimCLR self-supervised ê°€ì¤‘ì¹˜ë¡œ ì´ˆê¸°í™” â†’ ë™ì¼í•œ DeepLabV3 í—¤ë“œë¥¼ ë¶™ì—¬ fine-tune
2. **ì „ì²˜ë¦¬(Normalization) íŒŒì´í”„ë¼ì¸**
    - **Baseline**: A.Resizeâ†’A.Normalize(mean,std)â†’ToTensorV2
    - **SimCLR**: A.Resizeâ†’ToTensorV2 â†’ ëª¨ë¸ ì…ë ¥ ì „ì— .float().div(255.0)
3. **í•™ìŠµ ìŠ¤ì¼€ì¤„**
    - **Baseline**: ë°±ë³¸ê³¼ í—¤ë“œë¥¼ ë™ì¼í•œ learning rateë¡œ í•™ìŠµ
    - **SimCLR**: ë°±ë³¸ì€ ë‚®ì€ lr, í—¤ë“œëŠ” ë†’ì€ lrìœ¼ë¡œ ë‘ ë‹¨ê³„ ìŠ¤ì¼€ì¤„ë§